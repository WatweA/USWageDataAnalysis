{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Regression Models to Predict Income\n",
    "## **A Notebook for Using Demographic Data to Predict Income/Wage**"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data from pickles, and separate into the features/targets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log(message):\n",
    "    print(datetime.now().strftime(\"%H:%M:%S -\"), message)\n",
    "    \n",
    "def printnow():\n",
    "    print(datetime.now().strftime(\"Current time: %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:42:00 - Reading data\n22:42:16 - Done\n\n"
    }
   ],
   "source": [
    "log('Reading data')\n",
    "us_personal = pd.read_pickle('preprocessed_data/onehot_data.zip')\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler # a scaler to overcome outliers from the data\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor # baseline regression models\n",
    "from keras import Sequential # all relevant imports for Keras (TensorFlow based neural net)\n",
    "from keras.layers import Dense, LeakyReLU, ELU\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# metrics to exaluate the performance of our regressors\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:42:19 - Splitting Train/Test Data\n22:42:40 - Scaling Train/Test Features\n22:43:06 - Done\n\n"
    }
   ],
   "source": [
    "# Separate the data into three groups: incomes or wages (targets), and features (all other columns)\n",
    "# and return a corresponding dictionary with the three sets\n",
    "def features_targets(df):\n",
    "    features = df.drop(columns=['PINCP', 'WAGP'])\n",
    "    incomes = df['PINCP']\n",
    "    wages = df['WAGP']\n",
    "    return {'features':features, 'incomes':incomes, 'wages':wages}\n",
    "\n",
    "# create a dictionary representing the three sets and their features/targets\n",
    "log('Splitting Train/Test Data')\n",
    "train, test = train_test_split(us_personal, test_size=0.2)\n",
    "dataset = {\n",
    "    'train':features_targets(train),\n",
    "    'test':features_targets(test)}\n",
    "\n",
    "\n",
    "# Initialize the RobustScaler on the training data (fit before training each regression model)\n",
    "log('Scaling Train/Test Features')\n",
    "robust_scaler = RobustScaler().fit(dataset['train']['features'])\n",
    "dataset['train']['features'] = robust_scaler.transform(dataset['train']['features'])\n",
    "dataset['test']['features'] = robust_scaler.transform(dataset['test']['features'])\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to fit, test, and print results of a given estimator for a given target column\n",
    "def fit_test_print(estimator, estimator_name, target, target_name, grid=1):\n",
    "    log(f'Training {estimator_name}')\n",
    "    estimator.fit(dataset['train']['features'], dataset['train'][target].array)\n",
    "    y_pred_train = estimator.predict(dataset['train']['features'])\n",
    "    y_pred_test = estimator.predict(dataset['test']['features'])\n",
    "    log('Done\\n')\n",
    "    \n",
    "    print(f\"Results for {target_name} with {estimator_name}\")\n",
    "    if grid == 1: print(f\"- Best parameters: {estimator.best_params_}\")\n",
    "\n",
    "    print(f\"- Training Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['train'][target], y_pred_train)}\")\n",
    "\n",
    "    print(f\"- Test Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['test'][target], y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Implemented with ElasticNet, which combines L1 and L2 regularization"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_params = {\n",
    "    'alpha':[0.01, 0.1, 1, 10],\n",
    "    'l1_ratio':[0.25, 0.50, 0.75, 1]\n",
    "}\n",
    "\n",
    "linear_model_i = GridSearchCV(estimator=ElasticNet(), param_grid=linear_model_params, \n",
    "                            scoring=['neg_median_absolute_error', 'r2'], refit='r2', cv=4)\n",
    "linear_model_w = GridSearchCV(estimator=ElasticNet(), param_grid=linear_model_params, \n",
    "                            scoring=['neg_median_absolute_error', 'r2'], refit='r2', cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16:14:08 - Training Linear Model L1/L2 Regularized\n16:26:53 - Done\n\nResults for Income with Linear Model L1/L2 Regularized\n- Best parameters: {'alpha': 10, 'l1_ratio': 0.6}\n- Training Set\n\tMean Squared Error: 3274596194.857993\n\tMedian Absolute Error: 22929.83070571476\n\tr-Squared: 0.11891055597779776\n- Test Set\n\tMean Squared Error: 3281850782.70632\n\tMedian Absolute Error: 22924.74442348032\n\tr-Squared: 0.11853319389596961\n"
    }
   ],
   "source": [
    "fit_test_print(linear_model_i, 'Linear Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16:29:04 - Training Linear Model L1/L2 Regularized\n16:37:42 - Done\n\nResults for Wage with Linear Model L1/L2 Regularized\n- Best parameters: {'alpha': 10, 'l1_ratio': 0.6}\n- Training Set\n\tMean Squared Error: 2351956604.698796\n\tMedian Absolute Error: 17558.869250567495\n\tr-Squared: 0.15201561556297183\n- Test Set\n\tMean Squared Error: 2333282440.602135\n\tMedian Absolute Error: 17562.433428652887\n\tr-Squared: 0.15276740461628124\n"
    }
   ],
   "source": [
    "fit_test_print(linear_model_w, 'Linear Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regression\n",
    "Loss set to Huber to be more robust to outliers in income and wage"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model_params = {\n",
    "    'alpha':[0.000001, 0.00001, 0.0001, 0.001]\n",
    "}\n",
    "\n",
    "sgd_model_i = GridSearchCV(estimator=SGDRegressor(penalty='elasticnet', learning_rate='adaptive'), param_grid=sgd_model_params, cv=4)\n",
    "sgd_model_w = GridSearchCV(estimator=SGDRegressor(penalty='elasticnet', learning_rate='adaptive'), param_grid=sgd_model_params, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:43:06 - Training SGD Model L1/L2 Regularized\n23:35:27 - Done\n\nResults for Income with SGD Model L1/L2 Regularized\n- Best parameters: {'alpha': 0.0001}\n- Training Set\n\tMean Squared Error: 2313730116.8329206\n\tMedian Absolute Error: 12513.364387014095\n\tr-Squared: 0.3787176688793734\n- Test Set\n\tMean Squared Error: 2288257245.7425137\n\tMedian Absolute Error: 12522.970271169928\n\tr-Squared: 0.380348437367074\n"
    }
   ],
   "source": [
    "fit_test_print(sgd_model_i, 'SGD Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:35:28 - Training Logistic Model L1/L2 Regularized\n00:21:39 - Done\n\nResults for Wage with Logistic Model L1/L2 Regularized\n- Best parameters: {'alpha': 0.0001}\n- Training Set\n\tMean Squared Error: 1565194628.2093012\n\tMedian Absolute Error: 9285.146097658673\n\tr-Squared: 0.4363179455367291\n- Test Set\n\tMean Squared Error: 1536207636.0796754\n\tMedian Absolute Error: 9283.257766323872\n\tr-Squared: 0.4396291032552606\n"
    }
   ],
   "source": [
    "fit_test_print(sgd_model_w, 'Logistic Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Neural Net Regression\n",
    "Implemented with feed-forward dense layers "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to initialize the model\n",
    "def init_keras():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=151))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(200))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(50))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(20))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='huber_loss', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "nn_model_i = KerasRegressor(build_fn=init_keras, epochs=50, batch_size=32, verbose=1)\n",
    "nn_model_w = KerasRegressor(build_fn=init_keras, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "00:29:41 - Training Keras Neural Net\nEpoch 1/50\n2571631/2571631 [==============================] - 176s 69us/step - loss: 17270.2945 - mean_absolute_error: 17270.8086 - cosine_proximity: 0.7193\nEpoch 2/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16832.5715 - mean_absolute_error: 16832.9355 - cosine_proximity: 0.7194\nEpoch 3/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16707.9343 - mean_absolute_error: 16708.3223 - cosine_proximity: 0.7192\nEpoch 4/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16629.6131 - mean_absolute_error: 16629.9766 - cosine_proximity: 0.7189\nEpoch 5/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16573.3254 - mean_absolute_error: 16573.9473 - cosine_proximity: 0.7187\nEpoch 6/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16533.2628 - mean_absolute_error: 16533.7871 - cosine_proximity: 0.7187\nEpoch 7/50\n2571631/2571631 [==============================] - 195s 76us/step - loss: 16500.5068 - mean_absolute_error: 16500.9688 - cosine_proximity: 0.7187\nEpoch 8/50\n2571631/2571631 [==============================] - 202s 79us/step - loss: 16474.3732 - mean_absolute_error: 16474.8262 - cosine_proximity: 0.7188\nEpoch 9/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16448.4880 - mean_absolute_error: 16448.9355 - cosine_proximity: 0.7187\nEpoch 10/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16429.7040 - mean_absolute_error: 16430.3223 - cosine_proximity: 0.7186\nEpoch 11/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16413.1744 - mean_absolute_error: 16413.7598 - cosine_proximity: 0.7185\nEpoch 12/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16395.6441 - mean_absolute_error: 16396.1074 - cosine_proximity: 0.7184\nEpoch 13/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16378.8971 - mean_absolute_error: 16379.4395 - cosine_proximity: 0.7181\nEpoch 14/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16365.1472 - mean_absolute_error: 16365.5254 - cosine_proximity: 0.7182\nEpoch 15/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16350.4945 - mean_absolute_error: 16350.9004 - cosine_proximity: 0.7183\nEpoch 16/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16340.2385 - mean_absolute_error: 16340.7441 - cosine_proximity: 0.7182\nEpoch 17/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16328.9182 - mean_absolute_error: 16329.4990 - cosine_proximity: 0.7181\nEpoch 18/50\n2571631/2571631 [==============================] - 202s 78us/step - loss: 16318.8771 - mean_absolute_error: 16319.3740 - cosine_proximity: 0.7182\nEpoch 19/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16305.3823 - mean_absolute_error: 16305.8682 - cosine_proximity: 0.7180\nEpoch 20/50\n2571631/2571631 [==============================] - 202s 78us/step - loss: 16297.0656 - mean_absolute_error: 16297.5508 - cosine_proximity: 0.7180\nEpoch 21/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16286.2920 - mean_absolute_error: 16286.7510 - cosine_proximity: 0.7182\nEpoch 22/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16278.7739 - mean_absolute_error: 16279.3525 - cosine_proximity: 0.7178\nEpoch 23/50\n2571631/2571631 [==============================] - 206s 80us/step - loss: 16266.7609 - mean_absolute_error: 16267.2490 - cosine_proximity: 0.7180\nEpoch 24/50\n2571631/2571631 [==============================] - 197s 77us/step - loss: 16258.1886 - mean_absolute_error: 16258.5762 - cosine_proximity: 0.7179\nEpoch 25/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16249.7400 - mean_absolute_error: 16250.3262 - cosine_proximity: 0.7177\nEpoch 26/50\n2571631/2571631 [==============================] - 195s 76us/step - loss: 16242.1645 - mean_absolute_error: 16242.7568 - cosine_proximity: 0.7178\nEpoch 27/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16233.9031 - mean_absolute_error: 16234.2559 - cosine_proximity: 0.7176\nEpoch 28/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16224.7533 - mean_absolute_error: 16225.3193 - cosine_proximity: 0.7178\nEpoch 29/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16218.9304 - mean_absolute_error: 16219.4199 - cosine_proximity: 0.7176\nEpoch 30/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16212.6752 - mean_absolute_error: 16213.1348 - cosine_proximity: 0.7178\nEpoch 31/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16203.7083 - mean_absolute_error: 16204.1514 - cosine_proximity: 0.7176\nEpoch 32/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16196.7774 - mean_absolute_error: 16197.1846 - cosine_proximity: 0.7176\nEpoch 33/50\n2571631/2571631 [==============================] - 182s 71us/step - loss: 16191.5743 - mean_absolute_error: 16192.1377 - cosine_proximity: 0.7178\nEpoch 34/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16183.9420 - mean_absolute_error: 16184.3291 - cosine_proximity: 0.7178\nEpoch 35/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16176.0959 - mean_absolute_error: 16176.7451 - cosine_proximity: 0.7176\nEpoch 36/50\n2571631/2571631 [==============================] - 182s 71us/step - loss: 16170.0848 - mean_absolute_error: 16170.5811 - cosine_proximity: 0.7177\nEpoch 37/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16164.8603 - mean_absolute_error: 16165.2773 - cosine_proximity: 0.7177\nEpoch 38/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16159.3687 - mean_absolute_error: 16159.8613 - cosine_proximity: 0.7177\nEpoch 39/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16150.9667 - mean_absolute_error: 16151.4883 - cosine_proximity: 0.7176\nEpoch 40/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16145.6221 - mean_absolute_error: 16146.0303 - cosine_proximity: 0.7177\nEpoch 41/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16138.8674 - mean_absolute_error: 16139.4453 - cosine_proximity: 0.7177\nEpoch 42/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16130.5661 - mean_absolute_error: 16131.0098 - cosine_proximity: 0.7176\nEpoch 43/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16127.1272 - mean_absolute_error: 16127.6309 - cosine_proximity: 0.7177\nEpoch 44/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16120.1583 - mean_absolute_error: 16120.5967 - cosine_proximity: 0.7175\nEpoch 45/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16113.8772 - mean_absolute_error: 16114.3740 - cosine_proximity: 0.7176\nEpoch 46/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16109.4611 - mean_absolute_error: 16109.8252 - cosine_proximity: 0.7175\nEpoch 47/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16102.3518 - mean_absolute_error: 16102.8008 - cosine_proximity: 0.7176\nEpoch 48/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16097.8712 - mean_absolute_error: 16098.3301 - cosine_proximity: 0.7178\nEpoch 49/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 16089.5879 - mean_absolute_error: 16090.1094 - cosine_proximity: 0.7175\nEpoch 50/50\n2571631/2571631 [==============================] - 211s 82us/step - loss: 16085.4567 - mean_absolute_error: 16085.9609 - cosine_proximity: 0.7176\n2571631/2571631 [==============================] - 56s 22us/step\n642908/642908 [==============================] - 14s 22us/step\n03:11:25 - Done\n\nResults for Income with Keras Neural Net\n- Training Set\n\tMean Squared Error: 2042122702.2769258\n\tMedian Absolute Error: 5002.96484375\n\tr-Squared: 0.4516496355064821\n- Test Set\n\tMean Squared Error: 2101368726.2001605\n\tMedian Absolute Error: 5240.8330078125\n\tr-Squared: 0.43095715427949255\n"
    }
   ],
   "source": [
    "fit_test_print(nn_model_i, 'Keras Neural Net', 'incomes', 'Income', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "03:11:26 - Training Keras Neural Net\nEpoch 1/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 11071.2180 - mean_absolute_error: 11071.6953 - cosine_proximity: 0.4865\nEpoch 2/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10731.7060 - mean_absolute_error: 10732.1641 - cosine_proximity: 0.4863\nEpoch 3/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10654.8675 - mean_absolute_error: 10655.3721 - cosine_proximity: 0.4861\nEpoch 4/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10607.6285 - mean_absolute_error: 10608.1494 - cosine_proximity: 0.4860\nEpoch 5/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10567.5109 - mean_absolute_error: 10567.9746 - cosine_proximity: 0.4860\nEpoch 6/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10537.6260 - mean_absolute_error: 10538.1807 - cosine_proximity: 0.4860\nEpoch 7/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10515.0002 - mean_absolute_error: 10515.4609 - cosine_proximity: 0.4860\nEpoch 8/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10494.3852 - mean_absolute_error: 10494.8203 - cosine_proximity: 0.4860\nEpoch 9/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10477.2347 - mean_absolute_error: 10477.8145 - cosine_proximity: 0.4860\nEpoch 10/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10460.9865 - mean_absolute_error: 10461.4844 - cosine_proximity: 0.4859\nEpoch 11/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10448.5026 - mean_absolute_error: 10448.9824 - cosine_proximity: 0.4860\nEpoch 12/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10436.5392 - mean_absolute_error: 10436.9688 - cosine_proximity: 0.4860\nEpoch 13/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10422.7805 - mean_absolute_error: 10423.2256 - cosine_proximity: 0.4860\nEpoch 14/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10409.4268 - mean_absolute_error: 10409.8281 - cosine_proximity: 0.4861\nEpoch 15/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10402.3648 - mean_absolute_error: 10402.8662 - cosine_proximity: 0.4861\nEpoch 16/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10390.8440 - mean_absolute_error: 10391.3662 - cosine_proximity: 0.4861\nEpoch 17/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10380.5604 - mean_absolute_error: 10381.0977 - cosine_proximity: 0.4860\nEpoch 18/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10371.9619 - mean_absolute_error: 10372.3662 - cosine_proximity: 0.4860\nEpoch 19/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10363.5047 - mean_absolute_error: 10364.0166 - cosine_proximity: 0.4859\nEpoch 20/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10353.9440 - mean_absolute_error: 10354.4551 - cosine_proximity: 0.4860\nEpoch 21/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10347.3100 - mean_absolute_error: 10347.8340 - cosine_proximity: 0.4860\nEpoch 22/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10337.1015 - mean_absolute_error: 10337.5625 - cosine_proximity: 0.4860\nEpoch 23/50\n2571631/2571631 [==============================] - 189s 73us/step - loss: 10329.3469 - mean_absolute_error: 10329.9141 - cosine_proximity: 0.4860\nEpoch 24/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10323.4025 - mean_absolute_error: 10323.9238 - cosine_proximity: 0.4861\nEpoch 25/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10315.4786 - mean_absolute_error: 10315.9268 - cosine_proximity: 0.4859\nEpoch 26/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10307.6359 - mean_absolute_error: 10308.1670 - cosine_proximity: 0.4860\nEpoch 27/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10301.9685 - mean_absolute_error: 10302.4199 - cosine_proximity: 0.4859\nEpoch 28/50\n2571631/2571631 [==============================] - 189s 73us/step - loss: 10295.5981 - mean_absolute_error: 10296.1445 - cosine_proximity: 0.4860\nEpoch 29/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10289.3815 - mean_absolute_error: 10289.8848 - cosine_proximity: 0.4859\nEpoch 30/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10282.9550 - mean_absolute_error: 10283.4473 - cosine_proximity: 0.4860\nEpoch 31/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10278.9207 - mean_absolute_error: 10279.4229 - cosine_proximity: 0.4860\nEpoch 32/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10272.4560 - mean_absolute_error: 10272.9092 - cosine_proximity: 0.4860\nEpoch 33/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10264.1618 - mean_absolute_error: 10264.6699 - cosine_proximity: 0.4860\nEpoch 34/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10257.2614 - mean_absolute_error: 10257.7461 - cosine_proximity: 0.4859\nEpoch 35/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10253.2552 - mean_absolute_error: 10253.8223 - cosine_proximity: 0.4860\nEpoch 36/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10249.9122 - mean_absolute_error: 10250.3848 - cosine_proximity: 0.4859\nEpoch 37/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10241.6325 - mean_absolute_error: 10242.1562 - cosine_proximity: 0.4859\nEpoch 38/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10236.7527 - mean_absolute_error: 10237.1748 - cosine_proximity: 0.4860\nEpoch 39/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10234.0041 - mean_absolute_error: 10234.5781 - cosine_proximity: 0.4859\nEpoch 40/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10226.9890 - mean_absolute_error: 10227.5078 - cosine_proximity: 0.4860\nEpoch 41/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10221.4697 - mean_absolute_error: 10221.9053 - cosine_proximity: 0.4859\nEpoch 42/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10216.4533 - mean_absolute_error: 10216.9922 - cosine_proximity: 0.4859\nEpoch 43/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10211.4482 - mean_absolute_error: 10211.9639 - cosine_proximity: 0.4859\nEpoch 44/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10206.6492 - mean_absolute_error: 10207.1338 - cosine_proximity: 0.4858\nEpoch 45/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10202.2595 - mean_absolute_error: 10202.8730 - cosine_proximity: 0.4859\nEpoch 46/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10196.4120 - mean_absolute_error: 10196.9004 - cosine_proximity: 0.4859\nEpoch 47/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10192.1491 - mean_absolute_error: 10192.6553 - cosine_proximity: 0.4859\nEpoch 48/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10188.5916 - mean_absolute_error: 10189.0527 - cosine_proximity: 0.4859\nEpoch 49/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10183.3794 - mean_absolute_error: 10183.9033 - cosine_proximity: 0.4860\nEpoch 50/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10178.9267 - mean_absolute_error: 10179.4551 - cosine_proximity: 0.4859\n2571631/2571631 [==============================] - 58s 22us/step\n642908/642908 [==============================] - 15s 23us/step\n05:49:24 - Done\n\nResults for Wage with Keras Neural Net\n- Training Set\n\tMean Squared Error: 1189567093.7948844\n\tMedian Absolute Error: 13.535892486572266\n\tr-Squared: 0.5715947325225952\n- Test Set\n\tMean Squared Error: 1236934931.6712804\n\tMedian Absolute Error: 13.763057708740234\n\tr-Squared: 0.5487964513414394\n"
    }
   ],
   "source": [
    "fit_test_print(nn_model_w, 'Keras Neural Net', 'wages', 'Wage', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}