{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Regression Models to Predict Income\n",
    "## **A Notebook for Using Demographic Data to Predict Income/Wage**"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data from pickles, and separate into the features/targets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log(message):\n",
    "    print(datetime.now().strftime(\"%H:%M:%S -\"), message)\n",
    "    \n",
    "def printnow():\n",
    "    print(datetime.now().strftime(\"Current time: %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log('Reading data')\n",
    "us_personal = pd.read_pickle('preprocessed_data/onehot_data.zip')\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler # a scaler to overcome outliers from the data\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression # baseline regression models\n",
    "from keras import Sequential # all relevant imports for Keras (TensorFlow based neural net)\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# metrics to exaluate the performance of our regressors\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into three groups: incomes or wages (targets), and features (all other columns)\n",
    "# and return a corresponding dictionary with the three sets\n",
    "def features_targets(df):\n",
    "    features = df.drop(columns=['PINCP', 'WAGP'])\n",
    "    incomes = df['PINCP']\n",
    "    wages = df['WAGP']\n",
    "    return {'features':features, 'incomes':incomes, 'wages':wages}\n",
    "\n",
    "# create a dictionary representing the three sets and their features/targets\n",
    "log('Splitting Train/Test Data')\n",
    "train, test = train_test_split(us_personal, test_size=0.2)\n",
    "dataset = {\n",
    "    'train':features_targets(train),\n",
    "    'test':features_targets(test)}\n",
    "\n",
    "\n",
    "# Initialize the RobustScaler on the training data (fit before training each regression model)\n",
    "log('Scaling Train/Test Features')\n",
    "robust_scaler = RobustScaler().fit(dataset['train']['features'])\n",
    "dataset['train']['features'] = robust_scaler.transform(dataset['train']['features'])\n",
    "dataset['test']['features'] = robust_scaler.transform(dataset['test']['features'])\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to fit, test, and print results of a given estimator for a given target column\n",
    "def fit_test_print(estimator, estimator_name, target, target_name, grid=1):\n",
    "    log(f'Training {estimator_name}')\n",
    "    estimator.fit(dataset['train']['features'], dataset['train'][target])\n",
    "    y_pred_train = estimator.predict(dataset['train']['features'])\n",
    "    y_pred_test = estimator.predict(dataset['test']['features'])\n",
    "    log('Done\\n')\n",
    "    \n",
    "    print(f\"Results for {target_name} with {estimator_name}\")\n",
    "    if grid == 1: print(f\"- Best parameters: {estimator.best_params_}\")\n",
    "\n",
    "    print(f\"- Training Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['train'][target], y_pred_train)}\")\n",
    "\n",
    "    print(f\"- Test Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['test'][target], y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Implemented with ElasticNet, which combines L1 and L2 regularization"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_params = {\n",
    "    'alpha':[10, 100, 1000, 10000],\n",
    "    'l1_ratio':[0.40, 0.60]\n",
    "}\n",
    "\n",
    "linear_model = GridSearchCV(estimator=ElasticNet(), param_grid=linear_model_params, \n",
    "                            scoring=['neg_mean_absolute_error', 'r2'], \n",
    "                            refit='r2', n_jobs=4, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(linear_model, 'Linear Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(linear_model, 'Linear Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitc Regression"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_params = {\n",
    "    'C':[1, 10, 100, 1000],\n",
    "    'l1_ratio':[0, 0.5, 1]\n",
    "}\n",
    "\n",
    "logistic_model = GridSearchCV(estimator=LogisticRegression(solver='saga'), param_grid=logistic_model_params, \n",
    "                            scoring=['neg_mean_absolute_error', 'r2'], \n",
    "                            refit='r2', n_jobs=4, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(logistic_model, 'Logistic Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(logistic_model, 'Logistic Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Neural Net Regression\n",
    "Implemented with feed-forward dense layers "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to initialize the model\n",
    "def init_keras():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=151, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=['huber_loss'], optimizer='adam', metrics=['mean_absolute_error', 'cosine_proximity'])\n",
    "    return model\n",
    "\n",
    "neural_net_model = KerasRegressor(build_fn=init_keras, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(neural_net_model, 'Keras Neural Net', 'incomes', 'Income', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test_print(neural_net_model, 'Keras Neural Net', 'wages', 'Wage', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}