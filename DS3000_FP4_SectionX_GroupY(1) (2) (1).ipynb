{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Spring 2019</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Influence of US Demographic Factors on Personal Income </h3> </center>\n",
    "<center><h4>Aaditya Watwe, Arian Gokhale, Lily Olson, Alex Shaw</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "Add your summary here (100-150 words)\n",
    "\n",
    "Provide a brief summary of your project. After reading this executive summary, your readers should have a rough understanding of what you did in this project. You can think of this summary in terms of the four sections of the report and write 1-2 sentences describing each section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project decided to tackle understanding how different demographics can affect the personal income of individuals. We believe that there are some data visualizations tackling this issue, but many are highly politicized or hard to interpet. This has led to a lack of understanding on this topic by the general pulic. The topic of our project is determining to what degree an income gap exists and along which demographic borders does it fall. Some of our learning objectives include analyzing the gender-based income gap and the model minority theories. We would also like to analyze which demographic factors are the most significant in influencing one's income.\n",
    "\n",
    "This is an important problem to tackle, because without an unbiased understanding of the problem, we cannot create well informed public policy. The lack of concrete evidence towards either side of the political divide over this issue creates more misinformation and angst rather than approaching a solution. The insights derived from this project could show where the primary causes of income gaps are. Thus the problem is no longer the “income gap”, rather the problem will more clearly be identified (i.e. If the primary gap found is the lack of X race in Y industry, future studies could examine the cause of that phenomenon). There has been some research done in this area. A report titled Income and Wealth in the United States by the Peter G. Peterson Foundation found that incomes varied considerably between the coasts and the midwest and the south of the United States. Furthermore, income varied based on race/ethnicity, educational attainment, and gender. However, the analysis fozues on the median income levels, and does not produce any correlataional analysis (1). Other projects have looked into how the middle class has shrunk over time in America, but not dived into specifics of demographic data (2). \n",
    "\n",
    "Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "* To what degree do factors including gender, race, family wealth, geographic area, and occupational industry influence one's income?\n",
    "* To what extent does the gender-based income gap exist and are there deviations for different wealth brackets, races, or geographic areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "* Describe where you obtained your data. Provide a link to the original source. \n",
    "* If you scraped your data, include your code as a separate script file.\n",
    "* Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from local drive.\n",
    "* Describe the dataset and variables. What do variables represent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variables\n",
    "* For your hypotheses, what are your IVs and DVs?\n",
    "* For your predictive models, what are your features and target variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data Analysis\n",
    "* Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables?\n",
    "* Describe whether this is a supervised or unsupervised learning problem. Also identify the sub-category of the learning task (e.g. classification).\n",
    "* What machine learning algorithms are you going to use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling\n",
    "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
    "* Perform data wrangling to extract your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
    "* Preprocess your variables (e.g., scaling/transforming feature variables to normalize them)\n",
    "* Feature extraction (dummy variables, new features from existing features, etc.)\n",
    "* Use one feature selection technique to select a subset of your original features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration\n",
    "* Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "* You should have at least three visualizations (and at least two different visualization types)\n",
    "* For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "* If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and link those in Jupyter Notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Regression Models to Predict Income\n",
    "## **A Notebook for Using Demographic Data to Predict Income/Wage**"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data from pickles, and separate into the features/targets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log(message):\n",
    "    print(datetime.now().strftime(\"%H:%M:%S -\"), message)\n",
    "    \n",
    "def printnow():\n",
    "    print(datetime.now().strftime(\"Current time: %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:42:00 - Reading data\n22:42:16 - Done\n\n"
    }
   ],
   "source": [
    "log('Reading data')\n",
    "us_personal = pd.read_pickle('preprocessed_data/onehot_data.zip')\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler # a scaler to overcome outliers from the data\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor # baseline regression models\n",
    "from keras import Sequential # all relevant imports for Keras (TensorFlow based neural net)\n",
    "from keras.layers import Dense, LeakyReLU, ELU\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# metrics to exaluate the performance of our regressors\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:42:19 - Splitting Train/Test Data\n22:42:40 - Scaling Train/Test Features\n22:43:06 - Done\n\n"
    }
   ],
   "source": [
    "# Separate the data into three groups: incomes or wages (targets), and features (all other columns)\n",
    "# and return a corresponding dictionary with the three sets\n",
    "def features_targets(df):\n",
    "    features = df.drop(columns=['PINCP', 'WAGP'])\n",
    "    incomes = df['PINCP']\n",
    "    wages = df['WAGP']\n",
    "    return {'features':features, 'incomes':incomes, 'wages':wages}\n",
    "\n",
    "# create a dictionary representing the three sets and their features/targets\n",
    "log('Splitting Train/Test Data')\n",
    "train, test = train_test_split(us_personal, test_size=0.2)\n",
    "dataset = {\n",
    "    'train':features_targets(train),\n",
    "    'test':features_targets(test)}\n",
    "\n",
    "\n",
    "# Initialize the RobustScaler on the training data (fit before training each regression model)\n",
    "log('Scaling Train/Test Features')\n",
    "robust_scaler = RobustScaler().fit(dataset['train']['features'])\n",
    "dataset['train']['features'] = robust_scaler.transform(dataset['train']['features'])\n",
    "dataset['test']['features'] = robust_scaler.transform(dataset['test']['features'])\n",
    "log('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to fit, test, and print results of a given estimator for a given target column\n",
    "def fit_test_print(estimator, estimator_name, target, target_name, grid=1):\n",
    "    log(f'Training {estimator_name}')\n",
    "    estimator.fit(dataset['train']['features'], dataset['train'][target].array)\n",
    "    y_pred_train = estimator.predict(dataset['train']['features'])\n",
    "    y_pred_test = estimator.predict(dataset['test']['features'])\n",
    "    log('Done\\n')\n",
    "    \n",
    "    print(f\"Results for {target_name} with {estimator_name}\")\n",
    "    if grid == 1: print(f\"- Best parameters: {estimator.best_params_}\")\n",
    "\n",
    "    print(f\"- Training Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['train'][target], y_pred_train)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['train'][target], y_pred_train)}\")\n",
    "\n",
    "    print(f\"- Test Set\")\n",
    "    print(f\"\\tMean Squared Error: {mean_squared_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tMedian Absolute Error: {median_absolute_error(dataset['test'][target], y_pred_test)}\")\n",
    "    print(f\"\\tr-Squared: {r2_score(dataset['test'][target], y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Implemented with ElasticNet, which combines L1 and L2 regularization"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_params = {\n",
    "    'alpha':[0.01, 0.1, 1, 10],\n",
    "    'l1_ratio':[0.25, 0.50, 0.75, 1]\n",
    "}\n",
    "\n",
    "linear_model_i = GridSearchCV(estimator=ElasticNet(), param_grid=linear_model_params, \n",
    "                            scoring=['neg_median_absolute_error', 'r2'], refit='r2', cv=4)\n",
    "linear_model_w = GridSearchCV(estimator=ElasticNet(), param_grid=linear_model_params, \n",
    "                            scoring=['neg_median_absolute_error', 'r2'], refit='r2', cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16:14:08 - Training Linear Model L1/L2 Regularized\n16:26:53 - Done\n\nResults for Income with Linear Model L1/L2 Regularized\n- Best parameters: {'alpha': 10, 'l1_ratio': 0.6}\n- Training Set\n\tMean Squared Error: 3274596194.857993\n\tMedian Absolute Error: 22929.83070571476\n\tr-Squared: 0.11891055597779776\n- Test Set\n\tMean Squared Error: 3281850782.70632\n\tMedian Absolute Error: 22924.74442348032\n\tr-Squared: 0.11853319389596961\n"
    }
   ],
   "source": [
    "fit_test_print(linear_model_i, 'Linear Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16:29:04 - Training Linear Model L1/L2 Regularized\n16:37:42 - Done\n\nResults for Wage with Linear Model L1/L2 Regularized\n- Best parameters: {'alpha': 10, 'l1_ratio': 0.6}\n- Training Set\n\tMean Squared Error: 2351956604.698796\n\tMedian Absolute Error: 17558.869250567495\n\tr-Squared: 0.15201561556297183\n- Test Set\n\tMean Squared Error: 2333282440.602135\n\tMedian Absolute Error: 17562.433428652887\n\tr-Squared: 0.15276740461628124\n"
    }
   ],
   "source": [
    "fit_test_print(linear_model_w, 'Linear Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regression\n",
    "Loss set to Huber to be more robust to outliers in income and wage"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model_params = {\n",
    "    'alpha':[0.000001, 0.00001, 0.0001, 0.001]\n",
    "}\n",
    "\n",
    "sgd_model_i = GridSearchCV(estimator=SGDRegressor(penalty='elasticnet', learning_rate='adaptive'), param_grid=sgd_model_params, cv=4)\n",
    "sgd_model_w = GridSearchCV(estimator=SGDRegressor(penalty='elasticnet', learning_rate='adaptive'), param_grid=sgd_model_params, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:43:06 - Training SGD Model L1/L2 Regularized\n23:35:27 - Done\n\nResults for Income with SGD Model L1/L2 Regularized\n- Best parameters: {'alpha': 0.0001}\n- Training Set\n\tMean Squared Error: 2313730116.8329206\n\tMedian Absolute Error: 12513.364387014095\n\tr-Squared: 0.3787176688793734\n- Test Set\n\tMean Squared Error: 2288257245.7425137\n\tMedian Absolute Error: 12522.970271169928\n\tr-Squared: 0.380348437367074\n"
    }
   ],
   "source": [
    "fit_test_print(sgd_model_i, 'SGD Model L1/L2 Regularized', 'incomes', 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:35:28 - Training Logistic Model L1/L2 Regularized\n00:21:39 - Done\n\nResults for Wage with Logistic Model L1/L2 Regularized\n- Best parameters: {'alpha': 0.0001}\n- Training Set\n\tMean Squared Error: 1565194628.2093012\n\tMedian Absolute Error: 9285.146097658673\n\tr-Squared: 0.4363179455367291\n- Test Set\n\tMean Squared Error: 1536207636.0796754\n\tMedian Absolute Error: 9283.257766323872\n\tr-Squared: 0.4396291032552606\n"
    }
   ],
   "source": [
    "fit_test_print(sgd_model_w, 'Logistic Model L1/L2 Regularized', 'wages', 'Wage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Neural Net Regression\n",
    "Implemented with feed-forward dense layers "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to initialize the model\n",
    "def init_keras():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=151))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(200))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(50))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(20))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='huber_loss', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "nn_model_i = KerasRegressor(build_fn=init_keras, epochs=50, batch_size=32, verbose=1)\n",
    "nn_model_w = KerasRegressor(build_fn=init_keras, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "00:29:41 - Training Keras Neural Net\nEpoch 1/50\n2571631/2571631 [==============================] - 176s 69us/step - loss: 17270.2945 - mean_absolute_error: 17270.8086 - cosine_proximity: 0.7193\nEpoch 2/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16832.5715 - mean_absolute_error: 16832.9355 - cosine_proximity: 0.7194\nEpoch 3/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16707.9343 - mean_absolute_error: 16708.3223 - cosine_proximity: 0.7192\nEpoch 4/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16629.6131 - mean_absolute_error: 16629.9766 - cosine_proximity: 0.7189\nEpoch 5/50\n2571631/2571631 [==============================] - 198s 77us/step - loss: 16573.3254 - mean_absolute_error: 16573.9473 - cosine_proximity: 0.7187\nEpoch 6/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16533.2628 - mean_absolute_error: 16533.7871 - cosine_proximity: 0.7187\nEpoch 7/50\n2571631/2571631 [==============================] - 195s 76us/step - loss: 16500.5068 - mean_absolute_error: 16500.9688 - cosine_proximity: 0.7187\nEpoch 8/50\n2571631/2571631 [==============================] - 202s 79us/step - loss: 16474.3732 - mean_absolute_error: 16474.8262 - cosine_proximity: 0.7188\nEpoch 9/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16448.4880 - mean_absolute_error: 16448.9355 - cosine_proximity: 0.7187\nEpoch 10/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16429.7040 - mean_absolute_error: 16430.3223 - cosine_proximity: 0.7186\nEpoch 11/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16413.1744 - mean_absolute_error: 16413.7598 - cosine_proximity: 0.7185\nEpoch 12/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16395.6441 - mean_absolute_error: 16396.1074 - cosine_proximity: 0.7184\nEpoch 13/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16378.8971 - mean_absolute_error: 16379.4395 - cosine_proximity: 0.7181\nEpoch 14/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16365.1472 - mean_absolute_error: 16365.5254 - cosine_proximity: 0.7182\nEpoch 15/50\n2571631/2571631 [==============================] - 203s 79us/step - loss: 16350.4945 - mean_absolute_error: 16350.9004 - cosine_proximity: 0.7183\nEpoch 16/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16340.2385 - mean_absolute_error: 16340.7441 - cosine_proximity: 0.7182\nEpoch 17/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16328.9182 - mean_absolute_error: 16329.4990 - cosine_proximity: 0.7181\nEpoch 18/50\n2571631/2571631 [==============================] - 202s 78us/step - loss: 16318.8771 - mean_absolute_error: 16319.3740 - cosine_proximity: 0.7182\nEpoch 19/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16305.3823 - mean_absolute_error: 16305.8682 - cosine_proximity: 0.7180\nEpoch 20/50\n2571631/2571631 [==============================] - 202s 78us/step - loss: 16297.0656 - mean_absolute_error: 16297.5508 - cosine_proximity: 0.7180\nEpoch 21/50\n2571631/2571631 [==============================] - 201s 78us/step - loss: 16286.2920 - mean_absolute_error: 16286.7510 - cosine_proximity: 0.7182\nEpoch 22/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16278.7739 - mean_absolute_error: 16279.3525 - cosine_proximity: 0.7178\nEpoch 23/50\n2571631/2571631 [==============================] - 206s 80us/step - loss: 16266.7609 - mean_absolute_error: 16267.2490 - cosine_proximity: 0.7180\nEpoch 24/50\n2571631/2571631 [==============================] - 197s 77us/step - loss: 16258.1886 - mean_absolute_error: 16258.5762 - cosine_proximity: 0.7179\nEpoch 25/50\n2571631/2571631 [==============================] - 200s 78us/step - loss: 16249.7400 - mean_absolute_error: 16250.3262 - cosine_proximity: 0.7177\nEpoch 26/50\n2571631/2571631 [==============================] - 195s 76us/step - loss: 16242.1645 - mean_absolute_error: 16242.7568 - cosine_proximity: 0.7178\nEpoch 27/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16233.9031 - mean_absolute_error: 16234.2559 - cosine_proximity: 0.7176\nEpoch 28/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16224.7533 - mean_absolute_error: 16225.3193 - cosine_proximity: 0.7178\nEpoch 29/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16218.9304 - mean_absolute_error: 16219.4199 - cosine_proximity: 0.7176\nEpoch 30/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16212.6752 - mean_absolute_error: 16213.1348 - cosine_proximity: 0.7178\nEpoch 31/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16203.7083 - mean_absolute_error: 16204.1514 - cosine_proximity: 0.7176\nEpoch 32/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16196.7774 - mean_absolute_error: 16197.1846 - cosine_proximity: 0.7176\nEpoch 33/50\n2571631/2571631 [==============================] - 182s 71us/step - loss: 16191.5743 - mean_absolute_error: 16192.1377 - cosine_proximity: 0.7178\nEpoch 34/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16183.9420 - mean_absolute_error: 16184.3291 - cosine_proximity: 0.7178\nEpoch 35/50\n2571631/2571631 [==============================] - 184s 71us/step - loss: 16176.0959 - mean_absolute_error: 16176.7451 - cosine_proximity: 0.7176\nEpoch 36/50\n2571631/2571631 [==============================] - 182s 71us/step - loss: 16170.0848 - mean_absolute_error: 16170.5811 - cosine_proximity: 0.7177\nEpoch 37/50\n2571631/2571631 [==============================] - 183s 71us/step - loss: 16164.8603 - mean_absolute_error: 16165.2773 - cosine_proximity: 0.7177\nEpoch 38/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16159.3687 - mean_absolute_error: 16159.8613 - cosine_proximity: 0.7177\nEpoch 39/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16150.9667 - mean_absolute_error: 16151.4883 - cosine_proximity: 0.7176\nEpoch 40/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16145.6221 - mean_absolute_error: 16146.0303 - cosine_proximity: 0.7177\nEpoch 41/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16138.8674 - mean_absolute_error: 16139.4453 - cosine_proximity: 0.7177\nEpoch 42/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16130.5661 - mean_absolute_error: 16131.0098 - cosine_proximity: 0.7176\nEpoch 43/50\n2571631/2571631 [==============================] - 184s 72us/step - loss: 16127.1272 - mean_absolute_error: 16127.6309 - cosine_proximity: 0.7177\nEpoch 44/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16120.1583 - mean_absolute_error: 16120.5967 - cosine_proximity: 0.7175\nEpoch 45/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16113.8772 - mean_absolute_error: 16114.3740 - cosine_proximity: 0.7176\nEpoch 46/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16109.4611 - mean_absolute_error: 16109.8252 - cosine_proximity: 0.7175\nEpoch 47/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 16102.3518 - mean_absolute_error: 16102.8008 - cosine_proximity: 0.7176\nEpoch 48/50\n2571631/2571631 [==============================] - 185s 72us/step - loss: 16097.8712 - mean_absolute_error: 16098.3301 - cosine_proximity: 0.7178\nEpoch 49/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 16089.5879 - mean_absolute_error: 16090.1094 - cosine_proximity: 0.7175\nEpoch 50/50\n2571631/2571631 [==============================] - 211s 82us/step - loss: 16085.4567 - mean_absolute_error: 16085.9609 - cosine_proximity: 0.7176\n2571631/2571631 [==============================] - 56s 22us/step\n642908/642908 [==============================] - 14s 22us/step\n03:11:25 - Done\n\nResults for Income with Keras Neural Net\n- Training Set\n\tMean Squared Error: 2042122702.2769258\n\tMedian Absolute Error: 5002.96484375\n\tr-Squared: 0.4516496355064821\n- Test Set\n\tMean Squared Error: 2101368726.2001605\n\tMedian Absolute Error: 5240.8330078125\n\tr-Squared: 0.43095715427949255\n"
    }
   ],
   "source": [
    "fit_test_print(nn_model_i, 'Keras Neural Net', 'incomes', 'Income', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "03:11:26 - Training Keras Neural Net\nEpoch 1/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 11071.2180 - mean_absolute_error: 11071.6953 - cosine_proximity: 0.4865\nEpoch 2/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10731.7060 - mean_absolute_error: 10732.1641 - cosine_proximity: 0.4863\nEpoch 3/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10654.8675 - mean_absolute_error: 10655.3721 - cosine_proximity: 0.4861\nEpoch 4/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10607.6285 - mean_absolute_error: 10608.1494 - cosine_proximity: 0.4860\nEpoch 5/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10567.5109 - mean_absolute_error: 10567.9746 - cosine_proximity: 0.4860\nEpoch 6/50\n2571631/2571631 [==============================] - 186s 72us/step - loss: 10537.6260 - mean_absolute_error: 10538.1807 - cosine_proximity: 0.4860\nEpoch 7/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10515.0002 - mean_absolute_error: 10515.4609 - cosine_proximity: 0.4860\nEpoch 8/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10494.3852 - mean_absolute_error: 10494.8203 - cosine_proximity: 0.4860\nEpoch 9/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10477.2347 - mean_absolute_error: 10477.8145 - cosine_proximity: 0.4860\nEpoch 10/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10460.9865 - mean_absolute_error: 10461.4844 - cosine_proximity: 0.4859\nEpoch 11/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10448.5026 - mean_absolute_error: 10448.9824 - cosine_proximity: 0.4860\nEpoch 12/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10436.5392 - mean_absolute_error: 10436.9688 - cosine_proximity: 0.4860\nEpoch 13/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10422.7805 - mean_absolute_error: 10423.2256 - cosine_proximity: 0.4860\nEpoch 14/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10409.4268 - mean_absolute_error: 10409.8281 - cosine_proximity: 0.4861\nEpoch 15/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10402.3648 - mean_absolute_error: 10402.8662 - cosine_proximity: 0.4861\nEpoch 16/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10390.8440 - mean_absolute_error: 10391.3662 - cosine_proximity: 0.4861\nEpoch 17/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10380.5604 - mean_absolute_error: 10381.0977 - cosine_proximity: 0.4860\nEpoch 18/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10371.9619 - mean_absolute_error: 10372.3662 - cosine_proximity: 0.4860\nEpoch 19/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10363.5047 - mean_absolute_error: 10364.0166 - cosine_proximity: 0.4859\nEpoch 20/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10353.9440 - mean_absolute_error: 10354.4551 - cosine_proximity: 0.4860\nEpoch 21/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10347.3100 - mean_absolute_error: 10347.8340 - cosine_proximity: 0.4860\nEpoch 22/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10337.1015 - mean_absolute_error: 10337.5625 - cosine_proximity: 0.4860\nEpoch 23/50\n2571631/2571631 [==============================] - 189s 73us/step - loss: 10329.3469 - mean_absolute_error: 10329.9141 - cosine_proximity: 0.4860\nEpoch 24/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10323.4025 - mean_absolute_error: 10323.9238 - cosine_proximity: 0.4861\nEpoch 25/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10315.4786 - mean_absolute_error: 10315.9268 - cosine_proximity: 0.4859\nEpoch 26/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10307.6359 - mean_absolute_error: 10308.1670 - cosine_proximity: 0.4860\nEpoch 27/50\n2571631/2571631 [==============================] - 187s 73us/step - loss: 10301.9685 - mean_absolute_error: 10302.4199 - cosine_proximity: 0.4859\nEpoch 28/50\n2571631/2571631 [==============================] - 189s 73us/step - loss: 10295.5981 - mean_absolute_error: 10296.1445 - cosine_proximity: 0.4860\nEpoch 29/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10289.3815 - mean_absolute_error: 10289.8848 - cosine_proximity: 0.4859\nEpoch 30/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10282.9550 - mean_absolute_error: 10283.4473 - cosine_proximity: 0.4860\nEpoch 31/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10278.9207 - mean_absolute_error: 10279.4229 - cosine_proximity: 0.4860\nEpoch 32/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10272.4560 - mean_absolute_error: 10272.9092 - cosine_proximity: 0.4860\nEpoch 33/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10264.1618 - mean_absolute_error: 10264.6699 - cosine_proximity: 0.4860\nEpoch 34/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10257.2614 - mean_absolute_error: 10257.7461 - cosine_proximity: 0.4859\nEpoch 35/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10253.2552 - mean_absolute_error: 10253.8223 - cosine_proximity: 0.4860\nEpoch 36/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10249.9122 - mean_absolute_error: 10250.3848 - cosine_proximity: 0.4859\nEpoch 37/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10241.6325 - mean_absolute_error: 10242.1562 - cosine_proximity: 0.4859\nEpoch 38/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10236.7527 - mean_absolute_error: 10237.1748 - cosine_proximity: 0.4860\nEpoch 39/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10234.0041 - mean_absolute_error: 10234.5781 - cosine_proximity: 0.4859\nEpoch 40/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10226.9890 - mean_absolute_error: 10227.5078 - cosine_proximity: 0.4860\nEpoch 41/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10221.4697 - mean_absolute_error: 10221.9053 - cosine_proximity: 0.4859\nEpoch 42/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10216.4533 - mean_absolute_error: 10216.9922 - cosine_proximity: 0.4859\nEpoch 43/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10211.4482 - mean_absolute_error: 10211.9639 - cosine_proximity: 0.4859\nEpoch 44/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10206.6492 - mean_absolute_error: 10207.1338 - cosine_proximity: 0.4858\nEpoch 45/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10202.2595 - mean_absolute_error: 10202.8730 - cosine_proximity: 0.4859\nEpoch 46/50\n2571631/2571631 [==============================] - 188s 73us/step - loss: 10196.4120 - mean_absolute_error: 10196.9004 - cosine_proximity: 0.4859\nEpoch 47/50\n2571631/2571631 [==============================] - 190s 74us/step - loss: 10192.1491 - mean_absolute_error: 10192.6553 - cosine_proximity: 0.4859\nEpoch 48/50\n2571631/2571631 [==============================] - 189s 74us/step - loss: 10188.5916 - mean_absolute_error: 10189.0527 - cosine_proximity: 0.4859\nEpoch 49/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10183.3794 - mean_absolute_error: 10183.9033 - cosine_proximity: 0.4860\nEpoch 50/50\n2571631/2571631 [==============================] - 191s 74us/step - loss: 10178.9267 - mean_absolute_error: 10179.4551 - cosine_proximity: 0.4859\n2571631/2571631 [==============================] - 58s 22us/step\n642908/642908 [==============================] - 15s 23us/step\n05:49:24 - Done\n\nResults for Wage with Keras Neural Net\n- Training Set\n\tMean Squared Error: 1189567093.7948844\n\tMedian Absolute Error: 13.535892486572266\n\tr-Squared: 0.5715947325225952\n- Test Set\n\tMean Squared Error: 1236934931.6712804\n\tMedian Absolute Error: 13.763057708740234\n\tr-Squared: 0.5487964513414394\n"
    }
   ],
   "source": [
    "fit_test_print(nn_model_w, 'Keras Neural Net', 'wages', 'Wage', grid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Construction\n",
    "* If you proposed hypotheses, conduct your hypothesis tests\n",
    "* For your machine learning question(s), split data into training, validation, and testing sets (or use cross-validation)\n",
    "* Apply machine learning algorithms (apply at least three algorithms)\n",
    "* Train your algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "* Interpret your results from multiple models (and hypothesis tests, if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "* Provide a summary of the steps you took to analyze your data and test your predictive model\n",
    "* Intepret your findings from 3.4., 3.5, and 3.6\n",
    "    * Which algorithms did you compare?\n",
    "    * Which algorithm(s) revealed best performance?\n",
    "    * Which algorithm(s) should be used for your predictive model?\n",
    "* If you tested hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "\n",
    "* End this section with a conclusion paragraph containing some pointers for future work \n",
    "    *(e.g., get more data, perform another analysis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "* Describe each team member's contributions to the report (who did what in each section)\n",
    "* Remember this is a team effort!\n",
    "* Each member of your team will provide peer evaluation of other team members. Your final grade on the project will be based on those peer evaluations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
